# === AJOUTER AU D√âBUT DE api/app.py ===
from surprise import Dataset, Reader
from .load_save_data import *

def create_surprise_trainset(train_df):
    """Cr√©e un trainset pour le mod√®le surprise"""
    # Pr√©parer les donn√©es
    surprise_data = train_df[['userId', 'movieId', 'rating']].copy()
    surprise_data['userId'] = surprise_data['userId'].astype(str)
    surprise_data['movieId'] = surprise_data['movieId'].astype(str)
    surprise_data['rating'] = surprise_data['rating'].astype(float)
    
    # Cr√©er trainset
    reader = Reader(rating_scale=(0.5, 5.0))
    data = Dataset.load_from_df(surprise_data, reader)
    trainset = data.build_full_trainset()
    
    return trainset

def ensure_algo_has_trainset(algo, train_df):
    """S'assure que l'algorithme a un trainset"""
    if not hasattr(algo, 'trainset') or algo.trainset is None:
        # Cr√©er un trainset et r√©-entra√Æner
        trainset = create_surprise_trainset(train_df)
        algo.fit(trainset)
    return algo

def quick_compare_cloud_vs_local():
    """
    Comparaison rapide cloud vs local
    Retourne True si tout est identique, False sinon
    """
    try:
        # Donn√©es
        train_gcs, movies_gcs, ratings_gcs = load_data_from_gcs()
        train_local, movies_local, ratings_local = load_local_all_data()
        
        # V√©rification des dimensions
        if not (train_gcs.shape == train_local.shape and
                movies_gcs.shape == movies_local.shape and
                ratings_gcs.shape == ratings_local.shape):
            print("‚ö†Ô∏è Dimensions diff√©rentes")
            return False
        
        # V√©rification des colonnes
        datasets_gcs = [train_gcs, movies_gcs, ratings_gcs]
        datasets_local = [train_local, movies_local, ratings_local]
        names = ["train_ratings", "movies", "df_ratings"]
        
        for name, df_gcs, df_local in zip(names, datasets_gcs, datasets_local):
            if not set(df_gcs.columns) == set(df_local.columns):
                print(f"‚ö†Ô∏è Colonnes diff√©rentes pour {name}")
                return False
        
        # V√©rification des valeurs (√©chantillon)
        for name, df_gcs, df_local in zip(names, datasets_gcs, datasets_local):
            # Comparer les 100 premi√®res lignes
            sample_gcs = df_gcs.head(100)
            sample_local = df_local.head(100)
            
            if not sample_gcs.equals(sample_local):
                print(f"‚ö†Ô∏è Valeurs diff√©rentes pour {name}")
                return False
        
        # Mod√®les
        algo_gcs, user_enc_gcs, movie_enc_gcs = load_model_and_encoders_from_gcs()
        algo_local, user_enc_local, movie_enc_local = load_model_and_encoders_local()
        
        # V√©rifier les classes des encodeurs
        if (not np.array_equal(user_enc_gcs.classes_, user_enc_local.classes_) or
            not np.array_equal(movie_enc_gcs.classes_, movie_enc_local.classes_)):
            print("‚ö†Ô∏è Encodeurs diff√©rents")
            return False
        
        print("‚úÖ Toutes les donn√©es et mod√®les sont synchronis√©s")
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur lors de la comparaison: {e}")
        return False
    

def check_model_data_compatibility(algo, user_encoder, movie_encoder, train_df):
    """
    V√©rifie la compatibilit√© entre le mod√®le et les donn√©es
    """
    print("üîç V√©rification de compatibilit√© Mod√®le-Donn√©es")
    
    # 1. V√©rifier les colonnes n√©cessaires
    required_cols = {'user_idx', 'movie_idx'}
    available_cols = set(train_df.columns)
    
    if not required_cols.issubset(available_cols):
        print(f"‚ùå Colonnes manquantes dans train_df: {required_cols - available_cols}")
        return False
    
    print(f"‚úÖ Colonnes n√©cessaires pr√©sentes: {required_cols}")
    
    # 2. V√©rifier les plages d'indices
    unique_user_ids = train_df['user_idx'].unique()
    unique_movie_ids = train_df['movie_idx'].unique()
    
    print(f"üìä Plage user_idx: {unique_user_ids.min()} - {unique_user_ids.max()} (total: {len(unique_user_ids)})")
    print(f"üìä Plage movie_idx: {unique_movie_ids.min()} - {unique_movie_ids.max()} (total: {len(unique_movie_ids)})")
    
    # 3. V√©rifier avec les encodeurs
    if hasattr(user_encoder, 'classes_'):
        encoder_user_range = len(user_encoder.classes_)
        data_user_range = unique_user_ids.max() + 1  # indices commencent √† 0
        
        print(f"üë§ User encoder: {encoder_user_range} classes")
        print(f"üë§ Data user_idx max: {data_user_range}")
        
        if data_user_range > encoder_user_range:
            print(f"‚ö†Ô∏è Attention: user_idx dans donn√©es ({data_user_range}) > encoder ({encoder_user_range})")
            return False
    
    if hasattr(movie_encoder, 'classes_'):
        encoder_movie_range = len(movie_encoder.classes_)
        data_movie_range = unique_movie_ids.max() + 1
        
        print(f"üé¨ Movie encoder: {encoder_movie_range} classes")
        print(f"üé¨ Data movie_idx max: {data_movie_range}")
        
        if data_movie_range > encoder_movie_range:
            print(f"‚ö†Ô∏è Attention: movie_idx dans donn√©es ({data_movie_range}) > encoder ({encoder_movie_range})")
            return False
    
    # 4. Tester une pr√©diction simple - CORRECTION ICI
    try:
        test_user = unique_user_ids[0]
        test_movie = unique_movie_ids[0]
        
        # === MODIFICATION : Utiliser ensure_algo_has_trainset ===
        algo_with_trainset = ensure_algo_has_trainset(algo, train_df)
        prediction = algo_with_trainset.predict(test_user, test_movie)
        # === FIN MODIFICATION ===
        
        print(f"‚úÖ Test pr√©diction r√©ussi: user={test_user}, movie={test_movie}, rating={prediction.est}")
        return True
        
    except Exception as e:
        print(f"‚ùå Test pr√©diction √©chou√©: {e}")
        import traceback
        traceback.print_exc()
        return False