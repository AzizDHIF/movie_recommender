# ğŸ¬ Movie Recommendation System on GCP

[![GCP](https://img.shields.io/badge/Google_Cloud-4285F4?style=for-the-badge&logo=google-cloud&logoColor=white)](https://cloud.google.com/)
[![Python](https://img.shields.io/badge/Python-3.10-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-009688?style=for-the-badge&logo=fastapi&logoColor=white)](https://fastapi.tiangolo.com/)
[![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white)](https://streamlit.io/)

> A scalable movie recommendation system built on Google Cloud Platform, demonstrating real-time personalization as users interact with the system.

## ğŸ“‹ Table of Contents
- [Overview](#overview)
- [Architecture](#architecture)
- [Demo](#demo)
- [Technologies](#technologies)
- [Dataset](#dataset)
- [ML Model](#ml-model)
- [Installation](#installation)
- [Deployment](#deployment)
- [Usage](#usage)
- [Team](#team)

## ğŸ¯ Overview

This project implements an end-to-end movie recommendation system deployed on Google Cloud Platform. The system demonstrates how recommendations evolve as a new user progressively rates movies, showcasing the power of collaborative filtering in real-time.

**Key Features:**
- âœ… Real-time recommendations via REST API
- âœ… Interactive web interface with Streamlit
- âœ… Cloud-native architecture on GCP
- âœ… Scalable data pipeline with BigQuery
- âœ… Containerized deployment with Docker
- âœ… Progressive personalization demo

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             â”‚      â”‚              â”‚      â”‚             â”‚
â”‚  Streamlit  â”‚â”€â”€â”€â”€â–¶â”‚   FastAPI    â”‚â”€â”€â”€â”€â”€â–¶â”‚  BigQuery   â”‚
â”‚     UI      â”‚      â”‚  (Cloud Run) â”‚      â”‚             â”‚
â”‚             â”‚      â”‚              â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
                            â”‚                     â”‚
                            â–¼                     â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚    Cloud     â”‚      â”‚   Vertex    â”‚
                     â”‚   Storage    â”‚      â”‚     AI      â”‚
                     â”‚  (ML Model)  â”‚      â”‚ (Training)  â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Architecture Components

1. **Data Layer (BigQuery)**
   - Raw data storage (movies, ratings, users)
   - SQL-based preprocessing and aggregations
   - Fast querying for recommendations

2. **ML Layer (Vertex AI + Cloud Storage)**
   - Model training with SVD algorithms
   - Model versioning and storage
   - Experimentation tracking

3. **API Layer (Cloud Run)**
   - FastAPI REST API endpoints
   - Model inference and prediction
   - Scalable containerized deployment 

4. **Frontend Layer (Streamlit)**
   - Interactive user interface
   - Real-time rating input
   - Visual recommendation display

## ğŸ¥ Demo

### Progressive Recommendation Evolution

**Demo Workflow:**
1. **New User (No History)**: System shows popular movies
2. **After 2 Ratings**: Recommendations start personalizing based on genres (hybrid)
3. **After 11 Ratings**: Highly personalized suggestions using collaborative filtering

### Live Demo
ğŸŒ **API Endpoint**: `http://localhost:8501/`  
ğŸ–¥ï¸ **Web Interface**: `http://localhost:8501/`

## ğŸ› ï¸ Technologies

| Component | Technology | Purpose |
|-----------|------------|---------|
| Data Storage | **BigQuery** | Scalable data warehouse |
| ML Training | **Vertex AI** | Model training environment |
| Model Storage | **Cloud Storage** | Pickle model files and csv data files |
| API Backend | **FastAPI** | REST API framework |
| API Deployment | **Cloud Run** | Serverless container hosting |
| Frontend | **Streamlit** | Interactive web UI |
| Containerization | **Docker** | Application packaging |
| ML Algorithm | **SVD** | Collaborative filtering |

## ğŸ“Š Dataset

**Source**: [MovieLens Dataset](https://grouplens.org/datasets/movielens/)

**Statistics:**
- ğŸ“½ï¸ Movies: 10329
- ğŸ‘¥ Users: 668
- â­ Ratings: 84271
<!-- - ğŸ“… Time Period: 1995-2018 -->

**Features:**
```python
movies.csv
â”œâ”€â”€ movieId (int)
â”œâ”€â”€ title (str)
â””â”€â”€ genres (str)

ratings.csv
â”œâ”€â”€ userId (int)
â”œâ”€â”€ movieId (int)
â”œâ”€â”€ rating (float: 0.5-5.0)
â””â”€â”€ timestamp (int)
```

### Data Preprocessing
1. Label encoder for users index  and movies index
2. Create user-item interaction matrix
3. Split train/test (80/20)

## ğŸ¤– ML Model

### Algorithm: Singular Value Decomposition (SVD)

**Why SVD?**
- Captures latent factors in user-item interactions
- Handles sparse matrices efficiently
- Fast prediction time for real-time recommendations

### Model Performance
SVD:

| Metric | Value |
|--------|-------|
| RMSE (Test) | 0.8694 |
| MAE (Test) | 0.6672|
| Training Time | 1.4 seconds |
| Prediction Latency | 0.1 seconds |



### Training Pipeline
```bash
notebooks/
â”œâ”€â”€ 00_copier_creer_dataframes.ipynb # copying  the data
â”œâ”€â”€ 01_bigquery_analysis # first exploratory of the data
â”œâ”€â”€ 02_EDA  
â”œâ”€â”€ 03_preprocessing.ipynb      # creating encoders and train-test split 
â”œâ”€â”€ 04_training.ipynb 
â”œâ”€â”€ 05_comparaison_best_model
â”œâ”€â”€ 06_cold_start_analysis

â””â”€â”€ 
```

## ğŸš€ Installation

### Prerequisites
- Python 3.10+
- Docker
- Google Cloud SDK
- GCP Project with billing enabled

### Local Setup

```bash
# Clone repository
git clone https://github.com/votre-team/movie-recommender.git
cd movie-recommender

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Set environment variables
export PROJECT_ID="your-gcp-project"
export BUCKET_NAME="your-bucket-name"
export DATASET_ID="movielens"
```

### Run Locally

```bash
# Start FastAPI
cd api
uvicorn app:app --host 0.0.0.0 --port 8000

# In another terminal, start Streamlit
cd frontend
streamlit run streamlit_app.py
```

## â˜ï¸ Deployment

### 1. Setup GCP Resources

```bash
# Create BigQuery dataset
bq mk --dataset ${PROJECT_ID}:movielens

# Create Cloud Storage bucket
gsutil mb gs://${BUCKET_NAME}

# Upload data to BigQuery
bq load --source_format=CSV \
  movielens.movies \
  data/raw/movies.csv \
  movieId:INTEGER,title:STRING,genres:STRING
```

### 2. Deploy FastAPI to Cloud Run

```bash
cd api

# Build and push Docker image
gcloud builds submit --tag gcr.io/${PROJECT_ID}/movie-reco-api

# Deploy to Cloud Run
gcloud run deploy movie-reco-api \
  --image gcr.io/${PROJECT_ID}/movie-reco-api \
  --platform managed \
  --region europe-west1 \
  --allow-unauthenticated \
  --set-env-vars PROJECT_ID=${PROJECT_ID},BUCKET_NAME=${BUCKET_NAME}
```

### 3. Deploy Streamlit (Optional)

```bash
cd frontend

gcloud builds submit --tag gcr.io/${PROJECT_ID}/movie-reco-ui
gcloud run deploy movie-reco-ui \
  --image gcr.io/${PROJECT_ID}/movie-reco-ui \
  --platform managed \
  --region europe-west1 \
  --allow-unauthenticated \
  --set-env-vars API_URL=https://movie-reco-api-xxx.run.app
```

## ğŸ“– Usage

### API Endpoints

#### Get Recommendations
```bash
POST /predict
Content-Type: application/json

{
  "user_id": 123,
  "n_recommendations": 10
}
```

**Response:**
```json
{
  "user_id": 123,
  "recommendations": [
    {
      "movie_id": 318,
      "title": "The Shawshank Redemption (1994)",
      "predicted_rating": 4.8,
      "genres": "Crime|Drama"
    }
  ]
}
```

#### Add New Rating
```bash
POST /rate
Content-Type: application/json

{
  "user_id": 123,
  "movie_id": 318,
  "rating": 5.0
}
```

### Python SDK Example

```python
import requests

API_URL = "https://movie-reco-api-xxx.run.app"

# Get recommendations
response = requests.post(
    f"{API_URL}/predict",
    json={"user_id": 999, "n_recommendations": 5}
)
recommendations = response.json()

# Rate a movie
requests.post(
    f"{API_URL}/rate",
    json={"user_id": 999, "movie_id": 318, "rating": 5.0}
)

# Get updated recommendations
new_recs = requests.post(
    f"{API_URL}/predict",
    json={"user_id": 999}
).json()
```

## ğŸ“ˆ Progressive Recommendation Demo

### Scenario: New User Journey

```python
# Step 1: New user (no ratings)
# â†’ Receives popular movies

# Step 2: User rates 3 action movies highly
user_ratings = [
  {"movie": "The Dark Knight", "rating": 5.0},
  {"movie": "Inception", "rating": 4.5},
  {"movie": "The Matrix", "rating": 5.0}
]
# â†’ Recommendations shift to action/sci-fi

# Step 3: User rates 5 more diverse movies
# â†’ Recommendations become highly personalized

# Step 4: User continues rating
# â†’ System learns fine-grained preferences
```

**Key Observation**: Recommendations evolve from generic (popularity-based) to specific (collaborative filtering) as more ratings are provided.

## ğŸ§ª Testing

```bash
# Run unit tests
pytest tests/

# Test API locally
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"user_id": 1}'

# Load testing
locust -f tests/load_test.py --host https://movie-reco-api-xxx.run.app
```

## ğŸ“ Project Structure

```
movie_recommender/
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_preprocessing.ipynb
â”‚   â””â”€â”€ 03_model_training.ipynb
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ movies.csv
â”‚   â”‚   â””â”€â”€ ratings.csv
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ bigquery_queries.sql
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ saved_models/
â”‚   â”‚   â””â”€â”€ svd_model.pkl
â”‚   â””â”€â”€ model_evaluation.py
â”‚
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ tests/
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ streamlit_app.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ deployment/
â”‚   â”œâ”€â”€ deploy_cloudrun.sh
â”‚   â”œâ”€â”€ setup_bigquery.sql
â”‚   â””â”€â”€ setup_gcp.md
â”‚
â”œâ”€â”€ diagrams/
â”‚   â”œâ”€â”€ architecture.png
â”‚   â”œâ”€â”€ workflow.png
â”‚   â””â”€â”€ demo.gif
â”‚
â””â”€â”€ docs/
    â”œâ”€â”€ ARCHITECTURE.md
    â”œâ”€â”€ API_REFERENCE.md
    â””â”€â”€ USER_GUIDE.md
```

## ğŸ“ Key Learnings

1. **Cloud-Native Development**: Leveraging GCP services for scalability
2. **Real-Time ML**: Deploying models as REST APIs
3. **Progressive Personalization**: Demonstrating cold-start to warm-start transitions
4. **DevOps Practices**: CI/CD with Cloud Build, containerization with Docker
5. **Cost Optimization**: Using serverless (Cloud Run) for efficient resource usage

## ğŸš§ Challenges & Solutions

| Challenge | Solution |
|-----------|----------|
| Cold Start Problem | Hybrid approach: popularity + collaborative filtering |
| Large Model Size | Model compression + Cloud Storage caching |
| API Latency | Pre-computed recommendations for active users |
| Data Freshness | Scheduled BigQuery jobs for incremental updates |

## ğŸ“Š Performance Metrics

- **API Response Time**: < 200ms (p95)
- **Model Accuracy**: RMSE 0.87
- **System Uptime**: 99.9%
- **Cost per 1000 requests**: $0.05

## ğŸ”® Future Improvements

- [ ] Implement content-based filtering for better cold-start
- [ ] Add A/B testing framework
- [ ] Real-time model retraining with Vertex AI Pipelines
- [ ] Multi-armed bandit for exploration/exploitation
- [ ] User session tracking and analytics
- [ ] Mobile app (React Native)

## ğŸ‘¥ Team

- **Fatma Chahed** - Data Engineering & ML
- **Aziz Dhif** - Backend & API

## ğŸ“… Project Timeline

This project was completed over 4 weeks (1 month) with the following milestones:

### Week 1: Data & Exploration ğŸ“Š
**Goal**: Understand the data and set up infrastructure

| Day | Tasks | Deliverables |
|-----|-------|--------------|
| Day 1-2 | â€¢ Setup GCP project<br>â€¢ Create BigQuery dataset<br>â€¢ Upload MovieLens data | âœ… BigQuery tables populated<br>âœ… GCP environment ready |
| Day 3-4 | â€¢ Exploratory Data Analysis<br>â€¢ Data visualization<br>â€¢ Identify patterns | âœ… `01_data_exploration.ipynb`<br>âœ… Statistical insights |
| Day 5-7 | â€¢ Data preprocessing<br>â€¢ Handle missing values<br>â€¢ Feature engineering | âœ… `02_preprocessing.ipynb`<br>âœ… Clean dataset ready |

**Key Milestones**: 
- âœ… Dataset loaded in BigQuery
- âœ… EDA completed with insights
- âœ… Data cleaning pipeline established

---

### Week 2: Model Development ğŸ¤–
**Goal**: Train and evaluate recommendation model

| Day | Tasks | Deliverables |
|-----|-------|--------------|
| Day 1-2 | â€¢ Research recommendation algorithms<br>â€¢ Implement baseline model<br>â€¢ Setup Vertex AI (optional) | âœ… Algorithm comparison<br>âœ… Baseline metrics |
| Day 3-5 | â€¢ Train SVD/ALS model<br>â€¢ Hyperparameter tuning<br>â€¢ Model evaluation | âœ… `03_model_training.ipynb`<br>âœ… Trained model (RMSE < 1.0) |
| Day 6-7 | â€¢ Save model to Cloud Storage<br>â€¢ Test predictions<br>â€¢ Document model choices | âœ… Model artifacts stored<br>âœ… Evaluation report |

**Key Milestones**: 
- âœ… SVD model trained with RMSE 0.87
- âœ… Model stored in Cloud Storage
- âœ… Prediction function working

---

### Week 3: API & Deployment ğŸš€
**Goal**: Build and deploy REST API

| Day | Tasks | Deliverables |
|-----|-------|--------------|
| Day 1-2 | â€¢ Design API endpoints<br>â€¢ Build FastAPI app<br>â€¢ Integrate BigQuery + Storage | âœ… `api/app.py` functional<br>âœ… Swagger docs |
| Day 3-4 | â€¢ Create Dockerfile<br>â€¢ Test locally<br>â€¢ Write API tests | âœ… Containerized application<br>âœ… Unit tests passing |
| Day 5-7 | â€¢ Deploy to Cloud Run<br>â€¢ Configure environment variables<br>â€¢ Test production API | âœ… Public API URL<br>âœ… 99.9% uptime |

**Key Milestones**: 
- âœ… FastAPI with 3 endpoints operational
- âœ… Deployed on Cloud Run
- âœ… API response time < 200ms

---

### Week 4: Frontend & Polish âœ¨
**Goal**: Create UI and finalize documentation

| Day | Tasks | Deliverables |
|-----|-------|--------------|
| Day 1-3 | â€¢ Build Streamlit interface<br>â€¢ Connect to API<br>â€¢ Design user flow | âœ… `frontend/streamlit_app.py`<br>âœ… Interactive UI |
| Day 4-5 | â€¢ Test progressive recommendations<br>â€¢ Record demo video<br>â€¢ Take screenshots | âœ… Demo workflow validated<br>âœ… Demo assets |
| Day 6-7 | â€¢ Write comprehensive README<br>â€¢ Create architecture diagrams<br>â€¢ Prepare presentation | âœ… Complete documentation<br>âœ… Presentation ready |

**Key Milestones**: 
- âœ… Streamlit UI deployed/accessible
- âœ… Progressive personalization demo working
- âœ… GitHub repository polished
- âœ… Presentation materials complete

---

### Summary Timeline

```
Week 1: Data Foundation        [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 25%
Week 2: Model Development      [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘] 50%
Week 3: API & Deployment       [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 75%
Week 4: Frontend & Polish      [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100% âœ…
```

**Total Duration**: 4 weeks (160 hours)  
**Team Size**: 3-4 members  
**Technologies Mastered**: GCP, BigQuery, Vertex AI, FastAPI, Streamlit, Docker, Cloud Run

---
## ğŸ“„ License

This project is licensed under the MIT License - see [LICENSE](LICENSE) file.

## ğŸ™ Acknowledgments

- MovieLens for providing the dataset
- Google Cloud Platform for infrastructure
- FastAPI and Streamlit communities

---

**Project Link**: [https://github.com/votre-team/movie-recommender](https://github.com/votre-team/movie-recommender)

**Live Demo**: [https://movie-reco-ui-xxx.run.app](https://movie-reco-ui-xxx.run.app)

**Documentation**: [https://movie-recommender-docs.web.app](https://movie-recommender-docs.web.app)

---

â­ **Star this repo if you found it helpful!**




























